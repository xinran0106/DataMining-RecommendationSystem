{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "import ast\n",
    "import datetime\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_order = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "day_order = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "\n",
    "def clean_numeric(x):\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def get_month(x):\n",
    "    try:\n",
    "        return month_order[int(str(x).split('-')[1]) - 1]\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def get_day(x):\n",
    "    try:\n",
    "        year, month, day = (int(i) for i in x.split('-'))\n",
    "        answer = datetime.date(year, month, day).weekday()\n",
    "        return day_order[answer]\n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "\n",
    "def feature_engineering(df):\n",
    "    df['belongs_to_collection'] = df['belongs_to_collection'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "    for genre in genres_train:\n",
    "        df['is_' + str(genre)] = df['genres'].apply(lambda x: 1 if genre in x else 0)\n",
    "    df['genres'] = df['genres'].apply(lambda x: len(x))\n",
    "    df['homepage'] = df['homepage'].apply(lambda x: 0 if x == np.nan else 1)\n",
    "    df['is_english'] = df['original_language'].apply(lambda x: 1 if x=='en' else 0)\n",
    "    df = df.drop('original_language', axis=1)\n",
    "    df = df.drop('overview', axis=1)\n",
    "    df = df.drop('poster_path', axis=1)\n",
    "    for comp in ['Warner Bros','Universal Pictures','Paramount Pictures',\t'Twentieth Century Fox Film Corporation']:\n",
    "        df['is_' + str(comp)] = df['production_companies'].apply(lambda x: 1 if comp in x else 0)\n",
    "    for country in ['United States of America','United Kingdom']:\n",
    "        df['is_' + str(country)] = df['production_countries'].apply(lambda x: 1 if country in x else 0)\n",
    "    df = df.drop(['production_companies','production_countries'], axis=1)\n",
    "    df = df.drop('release_date', axis=1)\n",
    "    df = df.drop('status', axis=1)\n",
    "    df = df.drop('tagline', axis=1)\n",
    "    df = df.drop('title', axis=1)\n",
    "    df = df.drop('video', axis=1)\n",
    "#    df = pd.get_dummies(df, prefix='is')\n",
    "    df['runtime'] = df['runtime'].fillna(df['runtime'].mean())\n",
    "    df['vote_average'] = df['vote_average'].fillna(df['vote_average'].mean())\n",
    "    for day in day_order:\n",
    "        df['is_' + str(day)] = df['day'].apply(lambda x: 1 if day in x else 0)\n",
    "    for month in month_order:\n",
    "        df['is_' + str(month)] = df['month'].apply(lambda x: 1 if month in x else 0)\n",
    "    df = df.drop(['day','month'], axis=1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower().strip()\n",
    "    # Remove punctuation also numbers\n",
    "    text = re.sub('[^a-z]+', ' ', text)\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Tokenize text\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatize\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_text = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    # Re-join tokens into a string\n",
    "    return ' '.join(lemmatized_text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Data\n",
    "df = pd.read_csv('movies_metadata_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "\n",
    "df = df.drop(['imdb_id'], axis=1)\n",
    "df = df.drop('original_title', axis=1)\n",
    "df['revenue'] = df['revenue'].replace(0, np.nan)\n",
    "df['budget'] = pd.to_numeric(df['budget'], errors='coerce')\n",
    "df['budget'] = df['budget'].replace(0, np.nan)\n",
    "df['return'] = df['revenue'] / df['budget']\n",
    "df['year'] = pd.to_datetime(df['release_date'], errors='coerce').apply(lambda x: str(x).split('-')[0] if x != np.nan else np.nan)\n",
    "df = df.drop('adult', axis=1)\n",
    "\n",
    "df['production_countries'] = df['production_countries'].fillna('[]').apply(ast.literal_eval)\n",
    "df['production_countries'] = df['production_countries'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "df['production_companies'] = df['production_companies'].fillna('[]').apply(ast.literal_eval)\n",
    "df['production_companies'] = df['production_companies'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "\n",
    "df['popularity'] = df['popularity'].apply(clean_numeric).astype('float')\n",
    "df['vote_count'] = df['vote_count'].apply(clean_numeric).astype('float')\n",
    "df['vote_average'] = df['vote_average'].apply(clean_numeric).astype('float')\n",
    "\n",
    "df['vote_average'] = df['vote_average'].replace(0, np.nan)\n",
    "\n",
    "df['day'] = df['release_date'].apply(get_day)\n",
    "df['month'] = df['release_date'].apply(get_month)\n",
    "\n",
    "df['spoken_languages'] = df['spoken_languages'].fillna('[]').apply(ast.literal_eval).apply(lambda x: len(x) if isinstance(x, list) else np.nan)\n",
    "\n",
    "df['runtime'] = df['runtime'].astype('float')\n",
    "\n",
    "df['year'] = df['year'].replace('NaT', np.nan)\n",
    "df['year'] = df['year'].apply(clean_numeric)\n",
    "\n",
    "df['genres'] = df['genres'].fillna('[]').apply(ast.literal_eval).apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "\n",
    "\n",
    "s = df.apply(lambda x: pd.Series(x['genres']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "s.name = 'genre'\n",
    "gen_rgf = df.drop('genres', axis=1).join(s)\n",
    "genres_train = gen_rgf['genre'].drop_duplicates()\n",
    "\n",
    "\n",
    "data = df.copy()\n",
    "clean_df = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['combined_text'] = df['overview'].fillna('') + ' ' + df['tagline'].fillna('')\n",
    "\n",
    "# Apply text preprocessing\n",
    "df['processed_text'] = df['combined_text'].apply(preprocess_text)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=2, max_df=0.95)\n",
    "\n",
    "# Fit and transform the processed text\n",
    "tfidf_matrix = vectorizer.fit_transform(df['processed_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>UMAP Component 1</th>\n",
       "      <th>UMAP Component 2</th>\n",
       "      <th>id</th>\n",
       "      <th>cluster_0</th>\n",
       "      <th>cluster_1</th>\n",
       "      <th>cluster_2</th>\n",
       "      <th>cluster_3</th>\n",
       "      <th>cluster_4</th>\n",
       "      <th>cluster_5</th>\n",
       "      <th>cluster_6</th>\n",
       "      <th>cluster_7</th>\n",
       "      <th>cluster_8</th>\n",
       "      <th>cluster_9</th>\n",
       "      <th>cluster_10</th>\n",
       "      <th>cluster_11</th>\n",
       "      <th>cluster_12</th>\n",
       "      <th>cluster_13</th>\n",
       "      <th>cluster_14</th>\n",
       "      <th>cluster_15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12.306741</td>\n",
       "      <td>2.355496</td>\n",
       "      <td>862</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12.601574</td>\n",
       "      <td>4.976632</td>\n",
       "      <td>8844</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>13.944426</td>\n",
       "      <td>5.778309</td>\n",
       "      <td>15602</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12.983399</td>\n",
       "      <td>7.098469</td>\n",
       "      <td>31357</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4.362645</td>\n",
       "      <td>13.562076</td>\n",
       "      <td>11862</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  UMAP Component 1  UMAP Component 2     id  cluster_0  \\\n",
       "0           0         12.306741          2.355496    862      False   \n",
       "1           1         12.601574          4.976632   8844      False   \n",
       "2           2         13.944426          5.778309  15602      False   \n",
       "3           3         12.983399          7.098469  31357      False   \n",
       "4           4          4.362645         13.562076  11862      False   \n",
       "\n",
       "   cluster_1  cluster_2  cluster_3  cluster_4  cluster_5  cluster_6  \\\n",
       "0      False       True      False      False      False      False   \n",
       "1       True      False      False      False      False      False   \n",
       "2      False      False      False      False      False       True   \n",
       "3      False       True      False      False      False      False   \n",
       "4      False       True      False      False      False      False   \n",
       "\n",
       "   cluster_7  cluster_8  cluster_9  cluster_10  cluster_11  cluster_12  \\\n",
       "0      False      False      False       False       False       False   \n",
       "1      False      False      False       False       False       False   \n",
       "2      False      False      False       False       False       False   \n",
       "3      False      False      False       False       False       False   \n",
       "4      False      False      False       False       False       False   \n",
       "\n",
       "   cluster_13  cluster_14  cluster_15  \n",
       "0       False       False       False  \n",
       "1       False       False       False  \n",
       "2       False       False       False  \n",
       "3       False       False       False  \n",
       "4       False       False       False  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = pd.read_csv(\"movies_features.csv\")\n",
    "\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9082 entries, 0 to 9081\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Unnamed: 0        9082 non-null   int64  \n",
      " 1   UMAP Component 1  9082 non-null   float64\n",
      " 2   UMAP Component 2  9082 non-null   float64\n",
      " 3   id                9082 non-null   int64  \n",
      " 4   cluster_0         9082 non-null   bool   \n",
      " 5   cluster_1         9082 non-null   bool   \n",
      " 6   cluster_2         9082 non-null   bool   \n",
      " 7   cluster_3         9082 non-null   bool   \n",
      " 8   cluster_4         9082 non-null   bool   \n",
      " 9   cluster_5         9082 non-null   bool   \n",
      " 10  cluster_6         9082 non-null   bool   \n",
      " 11  cluster_7         9082 non-null   bool   \n",
      " 12  cluster_8         9082 non-null   bool   \n",
      " 13  cluster_9         9082 non-null   bool   \n",
      " 14  cluster_10        9082 non-null   bool   \n",
      " 15  cluster_11        9082 non-null   bool   \n",
      " 16  cluster_12        9082 non-null   bool   \n",
      " 17  cluster_13        9082 non-null   bool   \n",
      " 18  cluster_14        9082 non-null   bool   \n",
      " 19  cluster_15        9082 non-null   bool   \n",
      "dtypes: bool(16), float64(2), int64(2)\n",
      "memory usage: 425.8 KB\n"
     ]
    }
   ],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining TF-IDF Vector with Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=41)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(metric=&#x27;cosine&#x27;, n_neighbors=41)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(metric='cosine', n_neighbors=41)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_array = clean_df.values\n",
    "\n",
    "feature_array = new_df.values\n",
    "\n",
    "# Combine Features\n",
    "# combined_features = np.hstack((feature_array, tfidf_matrix.toarray()))\n",
    "\n",
    "# Imputing nan's with zeros\n",
    "combined_features = np.nan_to_num(feature_array)\n",
    "\n",
    "# Train your recommender model, for example, using Nearest Neighbors\n",
    "model = NearestNeighbors(n_neighbors=41, algorithm='auto', metric='cosine')\n",
    "model.fit(combined_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_filename = 'combined_features_array_v2.pkl'\n",
    "with open(array_filename, 'wb') as array_file:\n",
    "    pickle.dump(combined_features, array_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to a file\n",
    "model_filename = 'nearest_neighbors_model_v2.pkl'\n",
    "with open(model_filename, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  5 14 16 10  1  8 20 18 26 32 22 37 11  6 19 23  2 25  9 13 44 12 56\n",
      "   4 27 46  3 36 29 38 41 53 67 40  7 39 49 72 51 88]]\n"
     ]
    }
   ],
   "source": [
    "# Example function to get recommendations for a given movie\n",
    "def get_recommendations(movie_index):\n",
    "    distances, indices = model.kneighbors([combined_features[movie_index]])\n",
    "    return indices\n",
    "\n",
    "# Example usage: get recommendations for movie at index 0\n",
    "recommendations = get_recommendations(0)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.0), (1511, 5.745491082898013e-09), (1138, 1.740554846918485e-07), (3195, 2.378076876530244e-07), (6452, 2.6034964173415887e-07)]\n"
     ]
    }
   ],
   "source": [
    "# Example function to get recommendations for a given movie\n",
    "def get_recommendations(movie_index):\n",
    "    distances, indices = model.kneighbors([combined_features[movie_index]])\n",
    "    recommendations = list(zip(indices[0], distances[0]))\n",
    "    return recommendations\n",
    "\n",
    "# Example usage: get recommendations for movie at index 0\n",
    "recommendations = get_recommendations(0)\n",
    "print(recommendations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
